Log in to the control plane node.
Create configuration file for containerd.
Load modules.
Set system configurations for Kubernetes networking.
Apply new settings.
Install containerd.
Create default configuration file for containerd.
Generate default containerd configuration and save to the newly created default file.
Restart containerd to ensure new configuration file usage.
Verify that containerd is running.
Disable swap.
Install dependency packages.
Download and add GPG key.
Add Kubernetes to repository list.
Update package listings.
Install Kubernetes packages.
Turn off automatic updates.












Setting Up k8s Cluster



1.Set hostnames of control panel and worker nodes

sudo hostnamectl set-hostname k8s-control


2. Add host names to all the 3 servers


sudo vi /etc/hosts #edit this file

ip (private to be used as public changes if server restarted)    k8s-control
ip                                                               k8s-worker1
ip                                                               k8s-worker2


Relogin to all servers, now you can see hostnames being reflected.








1.Log in to the control plane node.

2.Create configuration file for containerd.

cat << EOF | sudo tee /etc/modules-load.d/containerd.conf
> overlay
> br_netfilter
> EOF


Info:
modprobe is a command in Linux and Unix operating systems that is used to add a kernel module to the operating system kernel.

Kernel modules are pieces of code that can be dynamically loaded and unloaded into the kernel at runtime. 
They can provide additional functionality to the kernel or support for specific hardware or software features.

The modprobe command searches for the specified module in the system's list of available kernel modules, and loads it into the kernel if it is not already loaded.
It can also load any dependent modules that are required by the specified module.

In Linux operating systems, tee is a command that reads input from standard input (stdin) and
writes it to both standard output (stdout) and one or more specified files.
The command is named after the "T" junction in plumbing, which splits a pipe into two.

Overlay and br_netfilter are two different concepts related to networking in Linux.


Overlay networking refers to the creation of virtual networks that are overlaid on top of physical networks. 
This allows for more flexible and dynamic network topologies, as virtual networks can be created, moved, and scaled independently of physical infrastructure.
Overlay networks are often used in containerized environments, where they allow containers to communicate with each other even if they are running on different hosts.

Br_netfilter, on the other hand, is a Linux kernel module that provides bridge-specific packet filtering capabilities. 
Bridges are devices that allow multiple network segments to be connected together, and br_netfilter provides the ability to filter traffic that passes through the bridge.
This can be useful for enforcing security policies or limiting network traffic.

Both overlay networking and br_netfilter are important tools for managing and securing network traffic in Linux environments. 
However, they serve different purposes and are used in different contexts. 
Overlay networking is typically used in cloud and containerized environments, while br_netfilter is more commonly used in traditional network infrastructure.




3.Load modules.

sudo modprobe overlay 
sudo modeprobe br_netfilter


4.Set system configurations for Kubernetes networking.


cat <<EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
>net.bridge.bridge-nf-call-iptables  = 1
>net.ipv4.ip_forward                 = 1
>net.bridge.bridge-nf-call-ip6tables = 1
>EOF

//net.bridge.bridge-nf-call-iptables = 1 is a kernel parameter setting in Linux systems that enables the iptables firewall to filter bridged network traffic. This parameter is typically used in virtualization environments where multiple virtual machines are connected to the same physical network interface via a bridge.

When set to 1, this parameter enables the kernel to pass bridged network traffic to iptables, which can then filter the traffic according to predefined rules. This helps to enhance the security of the virtual network by allowing administrators to restrict traffic between virtual machines or between virtual machines and the host system.

It's important to note that changing kernel parameters can have unintended consequences and should be done with caution. Also, this parameter may not be relevant or necessary in all environments, so it's important to understand your specific network configuration and security requirements before enabling it.//

//net.ipv4.ip_forward is a kernel parameter in Linux systems that enables or disables IP forwarding between network interfaces. When this parameter is set to 0, IP forwarding is disabled, and the system will only route packets between its own interfaces. When it is set to 1, IP forwarding is enabled, and the system will route packets between its own interfaces as well as between different networks.

This parameter is often used in network gateway devices or routers, where packets need to be forwarded between different networks. By default, IP forwarding is disabled in most Linux distributions to prevent accidental routing of packets and potential security risks.

It's important to note that enabling IP forwarding can introduce potential security risks, as it allows packets to be routed between different networks, potentially exposing sensitive data to unauthorized access. Therefore, it's important to carefully consider the security implications before enabling this parameter, and ensure that appropriate security measures are in place to protect the network.//

//net.bridge.bridge-nf-call-ip6tables = 1 is a kernel parameter setting in Linux systems that enables the ip6tables firewall to filter IPv6 bridged network traffic. This parameter is similar to the net.bridge.bridge-nf-call-iptables = 1 parameter used for IPv4 traffic, but is specific to IPv6 traffic.

When set to 1, this parameter enables the kernel to pass IPv6 bridged network traffic to ip6tables, which can then filter the traffic according to predefined rules. This helps to enhance the security of the virtual network by allowing administrators to restrict traffic between virtual machines or between virtual machines and the host system.

Just like with the net.bridge.bridge-nf-call-iptables = 1 parameter, changing this kernel parameter can have unintended consequences and should be done with caution. Additionally, not all systems may require this parameter, so it's important to understand your specific network configuration and security requirements before enabling it.//





5.Apply new settings.

sudo sysctl --system     

By running this command, any changes made to the system's kernel parameters in the /etc/sysctl.d/ directory will take effect immediately
without requiring a system reboot. This is useful for making changes to system settings without interrupting running services or applications.




6.Install containerd.

sudo apt-get update && sudo apt-get install -y containerd 


7.Create default configuration file for containerd.

sudo mkdir -p /etc/containerd


8.Generate default containerd configuration and save to the newly created default file.

sudo containerd config | /etc/containerd/config.toml

Overall, this command is used to generate and save a default configuration file for containerd in the appropriate location with superuser privileges.
This configuration file can be customized to modify the behavior of containerd and fine-tune its performance. 
The output of the command is also displayed to the console, allowing the user to review the configuration data.


9.Restart containerd to ensure new configuration file usage.

sudo systemctl restart containerd

10.Verify that containerd is running.

sudo systemctl status containerd

11.Disable swap.

The sudo swapoff -a command is used to disable all swap space on the system.

Swap space is a portion of a hard disk used for virtual memory when the system runs out of physical RAM. 
Kubernetes requires that swap space be disabled on all nodes in the cluster to ensure consistent and reliable performance.

Here's how this command works:

sudo runs the following command with superuser privileges, which is required to modify system-level settings.
swapoff is a command that disables swap space on the system.
-a is an option that tells swapoff to disable all swap spaces that are currently in use.

Overall, this command is typically used as part of the setup process for a Kubernetes cluster to ensure that swap space is disabled on all nodes in the cluster.
Disabling swap space can help prevent performance issues and unexpected behavior due to memory constraints.

12.Install dependency packages.

sudo apt-get update && sudo apt-get install -y apt-transport-https curl

The sudo apt-get install -y apt-transport-https curl command is used to install two packages: apt-transport-https and curl.
curl is a tool for transferring data from or to a server, using one of the supported protocols including HTTP, HTTPS, FTP, FTPS, SCP, SFTP, TFTP, DICT, TELNET, LDAP or FILE.


13.Download and add GPG key.

curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add 

sudo apt-key add - is a command that adds the downloaded key to the system's list of trusted keys. 
The - option tells the apt-key command to read the key from standard input.



The Google Cloud apt-key is a public key used to verify the authenticity of packages downloaded from the Google Cloud package repository.
The apt-key is used by the apt-get package manager to authenticate packages during installation.

When packages are uploaded to the Google Cloud package repository, they are signed with a private key to ensure their authenticity. 
The apt-key is the corresponding public key that can be used to verify the package signature and ensure that it was not tampered with during download or transmission.

By adding the Google Cloud apt-key to the system's trusted keyring, apt-get can verify the package signatures and
ensure that only authentic packages are installed on the system. 
This provides an additional layer of security and helps prevent malicious packages from being installed on the system.


14.Add Kubernetes to repository list.

cat << EOF | sudo /etc/apt/sources.list.d/kubernetes.list
>deb https://apt.kubernetes.io/ kubernetes-xenial main
>EOF



Overall, this command is used to add the Kubernetes package repository to the system's apt sources list by creating a new file named kubernetes.
list in the /etc/apt/sources.list.d directory and adding the repository's URL and distribution information to it.



Kubernetes is an open-source container orchestration system that allows developers to automate the deployment, scaling, 
and management of containerized applications. To simplify the management of Kubernetes deployments,
several package repositories are available to help users easily deploy and manage Kubernetes applications.

Some popular Kubernetes package repositories include:

Helm: Helm is a popular package manager for Kubernetes that allows users to define, install, and upgrade Kubernetes applications using charts,
which are packages that contain all the necessary Kubernetes resources to run an application.

Kubeapps: Kubeapps is a web-based Kubernetes application marketplace that allows users to discover, install, and manage applications on Kubernetes clusters.

OperatorHub: OperatorHub is a community-driven package repository for Kubernetes operators, which are Kubernetes-native applications
that can be used to automate complex tasks, such as managing databases or deploying applications.

Kompose: Kompose is a tool that allows users to convert Docker Compose files to Kubernetes YAML files, making it easier to deploy Docker Compose applications on Kubernetes.

ChartCenter: ChartCenter is a free and open-source public chart repository that provides a curated collection of Helm charts for popular applications.

There are also other package repositories available that offer similar functionality.
Users can choose the package repository that best meets their needs based on the types of applications they plan to deploy and manage on their Kubernetes cluster.

15.Update package listings.

sudo apt-get update

16.Install Kubernetes packages.

 sudo apt-get install -y kubelet=1.24.0-00 kubeadm=1.24.0-00 kubectl=1.24.0-00 

17.Turn off automatic updates.

sudo apt-mark hold kubelet kubeadm kubectl

When a package is marked as "held back," it means that it will not be automatically upgraded or installed during system updates. 
This is useful when you want to prevent accidental upgrades or modifications to critical system components.

In the context of Kubernetes, marking the kubelet, kubeadm, and kubectl packages as "held back" can help prevent unintended upgrades
that may cause compatibility issues or disrupt your Kubernetes cluster.
It's a recommended practice to use this command before upgrading or modifying your Kubernetes installation to ensure that you have a stable and consistent environment.



----Initialize the Cluster---------

On the control plane node, initialize the Kubernetes cluster on the control plane node using kubeadm:
Set kubectl access
Test access to cluster.



"sudo kubeadm init --pod-network-cidr 192.168.0/16 --kubernetes-version 1.24.0" is used to initialize a new Kubernetes cluster on a Linux system using the kubeadm tool.

command1
mkdir -p $HOME/.kube

By creating this directory, you are preparing your system to store the Kubernetes configuration file, which is used by kubectl, the Kubernetes command-line tool, 
to interact with your Kubernetes cluster. After creating the directory, you can copy your Kubernetes configuration file into it. 
This configuration file typically contains information about the API server, authentication credentials, 
and other cluster configuration details that kubectl needs to connect to and interact with your cluster.

command2
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config

 is used to copy the Kubernetes configuration file from the default location "/etc/kubernetes/admin.conf" to the user's home directory under the ".kube" subdirectory. 

This command is useful for setting up the Kubernetes configuration file, which is required by kubectl to communicate with the Kubernetes API server.
Once this command is executed, kubectl can be used to interact with the Kubernetes cluster using the configuration file stored in the user's home directory.

command3

sudo chown $(id -u) $(id -g) $HOME/.kube/config"

 is used to change the ownership of the Kubernetes configuration file to the current user. 

"$(id -u)": a command substitution that gets the user ID of the current user.

"$(id -g)": a command substitution that gets the group ID of the current user.
the purpose of this command is to ensure that the Kubernetes configuration file is owned by the user who will be using it, 
rather than being owned by the root user. This is important because kubectl will be looking for the configuration file in the user's home directory,
and may fail if the file is owned by another user. By changing the ownership of the file to the current user, you can avoid potential issues with kubectl 
and ensure that you have the necessary permissions to interact with the Kubernetes cluster.



----------Install the Calico Network Add-On------------

On the control plane node, install Calico Networking:
Check status of the control plane node.




kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml

 the URL of the YAML configuration file that describes the Calico networking plugin.
 This file contains information about the Calico components that will be deployed to the cluster, including the Calico node, 
 the Calico CNI plugin, and the Calico policy controller.

By running this command, you are instructing kubectl to download the Calico configuration file from the specified URL, 
and then deploy the Calico components to the Kubernetes cluster.
Once the components have been deployed, the Calico networking plugin will be available for use by the pods in your cluster.
Calico provides advanced networking and security features, including IP address management, network policy enforcement, 
and distributed firewalling, which can help you to secure and manage your Kubernetes workloads.

CNI stands for Container Networking Interface. It is a standard interface between the container runtime and
the networking plugin that provides networking capabilities to the containerized workloads running in a Kubernetes cluster.

CNI plugins are responsible for creating and managing network interfaces for containers, assigning IP addresses, and configuring routing and network policies.
They typically work with the underlying network infrastructure, such as virtual or physical network devices, 
to provide connectivity between containers and with external networks.




---------Join the Worker Nodes to the Cluster--------------

In the control plane node, create the token and copy the kubeadm join command:
Copy the full output from the previous command used in the control plane node. This command starts with kubeadm join.
In both worker nodes, paste the full kubeadm join command to join the cluster. Use sudo to run it as root
In the control plane node, view cluster status.



kubeadm token create --print-join-command

When you run this command, kubeadm will generate a new bootstrap token and print the command that can be used to join a new node to the cluster using this token. 
The join command includes the IP address and port of the Kubernetes API server,
as well as the bootstrap token and other configuration information that is needed to join the new node to the cluster.

You can copy this join command and use it on the new node that you want to join to the cluster.
By running this command on the new node, you can initiate the process of joining the node to the cluster, 
and the new node will be added to the cluster as a worker node.

Step 16:

Copy the command on both nodes



	You got your k8s setup !!!!
